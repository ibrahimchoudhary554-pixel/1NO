import streamlit as st
from openai import OpenAI
import os

# --- 1. UI & STYLING ---
st.set_page_config(page_title="Ibrahim's Intel Database", page_icon="üìÇ", layout="wide")

st.markdown("""
    <style>
    .stApp { background-color: #050505; color: #ffffff; }
    .watermark { position: fixed; bottom: 10px; right: 10px; opacity: 0.6; color: #ff4b4b; font-size: 14px; z-index: 99; font-weight: bold; }
    .model-box { border: 2px solid #ff4b4b; padding: 20px; border-radius: 10px; background-color: #1a0000; margin-bottom: 20px; }
    .disclaimer { border: 1px solid white; padding: 15px; background-color: #330000; color: white; text-align: center; border-radius: 5px; margin-bottom: 20px; }
    </style>
    <div class="watermark">OWNER: IBRAHIM | IG: @ibrahimchoudhary__</div>
    """, unsafe_allow_html=True)

# --- 2. DISCLAIMER & CRASH PROTECTION UI ---
st.markdown("""
    <div class="disclaimer">
        <strong>‚ö†Ô∏è AI DISCLAIMER:</strong> This bot uses Artificial Intelligence to retrieve information. 
        Ibrahim holds no personal foe or malice toward any individuals mentioned in the database. 
        All outputs are generated by AI based on stored data.
    </div>
    """, unsafe_allow_html=True)

with st.container():
    st.markdown('<div class="model-box">', unsafe_allow_html=True)
    st.subheader("‚öôÔ∏è System Control")
    model_choice = st.selectbox(
        "IF BOT CRASHES OR ACTS UP, SWITCH MODEL HERE:",
        ["Qwen/Qwen2.5-72B-Instruct", "mistralai/Mistral-7B-Instruct-v0.3", "meta-llama/Llama-3.1-8B-Instruct"]
    )
    st.warning("üö® **NOTE:** If the bot crashes, switch to another model above. Report bugs to: **@ibrahimchoudhary__**")
    st.markdown('</div>', unsafe_allow_html=True)

# --- 3. THE DATA READER ENGINE ---
def read_intel(query):
    if not os.path.exists("data.txt"):
        return "ERROR: data.txt not found. Upload the file to the root directory."
    
    with open("data.txt", "r", encoding="utf-8") as f:
        content = f.read()

    # Split the file by paragraphs/sections
    sections = content.split('\n\n')
    query_clean = query.lower().strip()
    
    # Filter only the sections that contain the searched name
    relevant_sections = [s for s in sections if query_clean in s.lower()]
    
    if relevant_sections:
        return "\n\n".join(relevant_sections)
    return "No specific data found in the file for this entry."

# --- 4. CHAT INTERFACE ---
if "messages" not in st.session_state:
    st.session_state.messages = []

for m in st.session_state.messages:
    with st.chat_message(m["role"]):
        st.markdown(m["content"])

if prompt := st.chat_input("Search for a name or topic in the database..."):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Search the file
    file_data = read_intel(prompt)

    with st.chat_message("assistant"):
        # The AI is now instructed ONLY to report what's in the file.
        system_instruction = f"""
        You are a Data Retrieval Assistant for Ibrahim.
        
        DATABASE CONTENT:
        {file_data}
        
        INSTRUCTIONS:
        1. Answer the user's question ONLY using the DATABASE CONTENT provided above.
        2. If the user asks about a person, give all the facts mentioned in the data.
        3. Do not add insults or roasts unless they are already written in the data.
        4. If the data is empty for that name, say "No information found on this individual in Ibrahim's records."
        5. Stay professional and factual.
        """

        try:
            client = OpenAI(base_url="https://router.huggingface.co/v1", api_key=st.secrets["HF_TOKEN"])
            response = client.chat.completions.create(
                model=model_choice,
                messages=[
                    {"role": "system", "content": system_instruction},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1, # Keep it extremely literal
                max_tokens=500
            )
            answer = response.choices[0].message.content
            st.markdown(answer)
            st.session_state.messages.append({"role": "assistant", "content": answer})
        except Exception as e:
            st.error("System connection lost. Switch models in the box above.")
